{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qahme/Dev/.virtualenvs/stock3/lib/python3.6/site-packages/ipykernel_launcher.py:39: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/qahme/Dev/.virtualenvs/stock3/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/qahme/Dev/.virtualenvs/stock3/lib/python3.6/site-packages/ipykernel_launcher.py:41: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/qahme/Dev/.virtualenvs/stock3/lib/python3.6/site-packages/ipykernel_launcher.py:42: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import unicodedata\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from utils import offset_value\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading the saved data pickle file\n",
    "df_stocks = pd.read_pickle(path.relpath(\"Data/my_pickled_one_year_filtered_lead_para.pkl\"))\n",
    "\n",
    "df_stocks['prices'] = df_stocks['adj close'].apply(np.int64)\n",
    "df_stocks = df_stocks[['prices', 'articles']]\n",
    "df_stocks['articles'] = df_stocks['articles'].map(lambda x: x.lstrip('.-'))\n",
    "df = df_stocks[['prices']].copy()\n",
    "# Adding new columns to the data frame\n",
    "df[\"compound\"] = ''\n",
    "df[\"neg\"] = ''\n",
    "df[\"neu\"] = ''\n",
    "df[\"pos\"] = ''\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for date, row in df_stocks.T.iteritems():\n",
    "    sentence = unicodedata.normalize('NFKD', df_stocks.loc[date, 'articles'])\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    df.set_value(date, 'compound', ss['compound'])\n",
    "    df.set_value(date, 'neg', ss['neg'])\n",
    "    df.set_value(date, 'neu', ss['neu'])\n",
    "    df.set_value(date, 'pos', ss['pos'])\n",
    "\n",
    "train_start_date = '2016-01-01'\n",
    "train_end_date = '2017-05-31'\n",
    "test_start_date = '2017-06-01'\n",
    "test_end_date = '2017-11-20'\n",
    "\n",
    "train = df.ix[train_start_date : train_end_date]\n",
    "test = df.ix[test_start_date:test_end_date]\n",
    "\n",
    "y_train = pd.DataFrame(train['prices'])\n",
    "y_test = pd.DataFrame(test['prices']) \n",
    "\n",
    "##Starts here\n",
    "years = [2016,2017]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-11-29'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        if(df.loc[date, 'compound'] != ''):\n",
    "            sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "            sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        if(df.loc[date, 'compound'] != ''):\n",
    "            sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "            #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "            sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "    mlpc.fit(numpy_df_train, train['prices']) \n",
    "\n",
    "    prediction = mlpc.predict(numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=20, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=20, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    fig = predictions_df_list.plot().get_figure()\n",
    "    fig.savefig(\"graphs/etherium/MLP_ether \"+str(year) +\".png\")\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    fig = predictions_df_list_average.plot().get_figure()\n",
    "    fig.savefig(\"graphs/etherium/MLP_average_ether\"+str(year) +\".png\")\n",
    "    \n",
    "\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='tanh', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False)\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False) # span = 20\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 50), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False)\n",
    "          \n",
    "# Generating models\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(numpy_df_train, train['prices'])\n",
    "\n",
    "# checking the performance of training data itself\n",
    "prediction, bias, contributions = ti.predict(rf, numpy_df_train)\n",
    "idx = pd.date_range(train_start_date, train_end_date)\n",
    "predictions_df1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "fig = predictions_df1.plot().get_figure()\n",
    "fig.savefig(path.relpath(\"graphs/etherium/MLP_p_ether.png\"))\n",
    "\n",
    "# predictions_df1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices', 'predicted price'])\n",
    "# fig = train['prices'].plot().get_figure()\n",
    "# fig.savefig(path.relpath(\"graphs/etherium/MLP_p2_ether.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
